<!doctype html><html lang=en-uk dir=ltr itemscope itemtype=http://schema.org/Article><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.137.0"><meta name=generator content="Relearn 7.1.1"><meta name=description content="Lecture/Assignment  plan and link to the individual lectures."><meta name=author content="Justin Pearson"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lectures :: AD2 Homepage"><meta name=twitter:description content="Lecture/Assignment  plan and link to the individual lectures."><meta property="og:url" content="https://ad2-uu-se.github.io/lectures/index.html"><meta property="og:site_name" content="AD2 Homepage"><meta property="og:title" content="Lectures :: AD2 Homepage"><meta property="og:description" content="Lecture/Assignment  plan and link to the individual lectures."><meta property="og:locale" content="en_uk"><meta property="og:type" content="website"><meta itemprop=name content="Lectures :: AD2 Homepage"><meta itemprop=description content="Lecture/Assignment  plan and link to the individual lectures."><meta itemprop=datePublished content="2020-08-19T11:41:46+02:00"><meta itemprop=dateModified content="2020-08-19T11:41:46+02:00"><meta itemprop=wordCount content="244"><title>Lectures :: AD2 Homepage</title>
<link href=https://ad2-uu-se.github.io/lectures/index.html rel=canonical type=text/html title="Lectures :: AD2 Homepage"><link href=/lectures/index.xml rel=alternate type=application/rss+xml title="Lectures :: AD2 Homepage"><link href=/css/fontawesome-all.min.css?1731417181 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css?1731417181 rel=stylesheet></noscript><link href=/css/nucleus.css?1731417181 rel=stylesheet><link href=/css/auto-complete.css?1731417181 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/auto-complete.css?1731417181 rel=stylesheet></noscript><link href=/css/perfect-scrollbar.min.css?1731417181 rel=stylesheet><link href=/css/fonts.css?1731417181 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fonts.css?1731417181 rel=stylesheet></noscript><link href=/css/theme.css?1731417181 rel=stylesheet><link href=/css/theme-blue.css?1731417181 rel=stylesheet id=R-variant-style><link href=/css/chroma-learn.css?1731417181 rel=stylesheet id=R-variant-chroma-style><link href=/css/print.css?1731417181 rel=stylesheet media=print><link href=/css/format-print.css?1731417181 rel=stylesheet><script src=/js/variant.js?1731417181></script><script>window.relearn=window.relearn||{},window.relearn.relBasePath="..",window.relearn.relBaseUri="..",window.relearn.absBaseUri="https://ad2-uu-se.github.io",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.variants&&variants.init(["blue"]),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script></head><body class="mobile-support print" data-url=/lectures/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>AD2 1DL231</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lectures</span><meta itemprop=position content="2"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/lectures/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/syllabus/index.html title="Syllabus (ðŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/lectures/lecture1/index.html title="Lecture 1 (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable lectures" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lectures>Lectures</h1><ul><li></li></ul><h2 id=lecture-help-sessions-and-grading-sessions-information>Lecture, help sessions and grading sessions information.</h2><p>There is a menu item for each lecture where you can find a reading
guide for the textbook, and links to additional material.</p><p>For the lecture locations please look at
<a href=https://cloud.timeedit.net/uu/web/wr_staff/ri1wQX9896ZZ7tQw7Q00t942yCY685Z7894Q707QQY3ZBY59694dBAED443C5DAB563C33C2FFD.phtml rel=external target=_blank>timeedit</a>. The
timeedit schedule is always correct. If there are any discrepancies
between this page and timeedit, then please inform me.</p><table><thead><tr><th>Lecture/Assignment</th><th>Date</th><th>Topic</th></tr></thead><tbody><tr><td>1</td><td>2024-11-04 15:15-17:00</td><td><a href=/lectures/lecture1/index.html>Introduction to the course and revision of Algorithm analysis</a></td></tr><tr><td>2</td><td>2023-11-05 13:15-15:00</td><td><a href=/lectures/lecture2/index.html>Divide and Conquer and Algorithm analysis</a></td></tr><tr><td>3</td><td>2024-11-06 10:15-12:00</td><td><a href=/lectures/lecture3/index.html>Revision of Graphs, and the Python API for the assignments</a> <a href="https://www.uu.se/en/contact-and-organisation/staff?query=N11-2347" rel=external target=_blank>(Frej Knutar Lewander)</a></td></tr><tr><td>4</td><td>2024-11-12 13:15-15:00</td><td><a href=/lectures/lecture4/index.html>Dynamic Programming - Introduction</a></td></tr><tr><td>Help 1a</td><td>2024-11-13 15:15-17:00</td><td></td></tr><tr><td>5</td><td>2024-11-15 10:15-12:00</td><td><a href=/lectures/lecture5/index.html>Dynamic Programming - Knapsack</a></td></tr><tr><td>Help 1b</td><td>2024-11-19 08:15-10:00</td><td></td></tr><tr><td>Help 1c</td><td>2024-11-21 10:15-12:00</td><td></td></tr><tr><td>Deadline Assignment 1</td><td>2024-11-22 13:00</td><td></td></tr><tr><td>6</td><td>2024-11-22 10:15-12:00</td><td><a href=/lectures/lecture6/index.html>Greedy Algorithms</a></td></tr><tr><td>7</td><td>2024-11-26 13:15-15:00</td><td><a href=/lectures/lecture7/index.html>Minimal Spanning Trees</a></td></tr><tr><td>Help 2a</td><td>2024-11-29 08:15-10:00</td><td></td></tr><tr><td>Grading session Assignment 1</td><td>2024-11-29 15:15-17:00</td><td>By invitation only</td></tr><tr><td>8</td><td>2024-12-02 10:15-12:00</td><td><a href=/lectures/lectures8-9/index.html>Network flows</a></td></tr><tr><td>Help 2b</td><td>2024-12-02 15:15-17:00</td><td></td></tr><tr><td>Solution Session Assignment 1</td><td>2024-12-03 13:15-14:00</td><td>Obs only 45 mins</td></tr><tr><td>9</td><td>2024-12-04 10:15-12:00</td><td><a href=/lectures/lectures8-9/index.html>Networks flows, Bipartite matching</a></td></tr><tr><td>Help 2c</td><td>2024-12-06 08:15-10:00</td><td></td></tr><tr><td>Deadline Assignment 2</td><td>2024-12-06 13:00</td><td></td></tr><tr><td>10</td><td>2024-12-09 13:15-15:00</td><td><a href=/lectures/lectures10-11/index.html>P vs NP</a> <a href=https://pierre-flener.github.io/ rel=external target=_blank>(Pierre Flener)</a></td></tr><tr><td>Help 3a</td><td>2024-12-10 10:15-12:00</td><td></td></tr><tr><td>11</td><td>2024-12-11 13:15-15:00</td><td><a href=/lectures/lectures10-11/index.html>P vs NP</a> <a href=https://pierre-flener.github.io/ rel=external target=_blank>(Pierre Flener)</a></td></tr><tr><td>Help 3b</td><td>2024-12-12 10:15-12:00</td><td></td></tr><tr><td>Solution Session Assignment 2</td><td>2024-12-16 11:15-12:00</td><td>Obs only 45 mins</td></tr><tr><td>12</td><td>2024-12-16 13:15-15:00</td><td><a href=/lectures/lecture12/index.html>Union Find</a></td></tr><tr><td>Help 3c</td><td>2024-12-18 10:15-12:00</td><td></td></tr><tr><td>13</td><td>2024-12-19 10:15-12:00</td><td><a href=/lectures/lecture13/index.html>String Matching</a></td></tr><tr><td>Deadline Assignment 3</td><td>2025-01-02 13:00</td><td></td></tr><tr><td>Exam</td><td>2025-01-08</td><td>TBA</td></tr></tbody></table><footer class=footline></footer></article><section><h1 class=a11y-only>Subsections of Lectures</h1><article class=default><header class=headline></header><h1 id=lecture-1>Lecture 1</h1><h2 id=todays-topics-introduction-and-asymptotic-analysis>Today&rsquo;s Topics: Introduction and asymptotic analysis</h2><ul><li>Introduction/revision on algorithm analysis</li><li>Worst case running time.</li><li>Introduction to asymptotic analysis $O$,$\Theta$ and $\Omega$.</li></ul><h2 id=links-to-slides-and-other-material>Links to Slides and other material</h2><ul><li><a href=https://ad2-uu-se.github.io/slides/00-Logistics.pdf rel=external target=_blank>Slides</a>
on introduction and logistics.</li><li><a href=https://ad2-uu-se.github.io/slides/01-analysis-bigoh-revision.pdf rel=external target=_blank>Slides</a>
on an asymptotic analysis.</li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li>Chapter 1,2, 3.1 and 3.2 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or <a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>How is the course structured? How do the assignments, help sessions
and labs work?</li><li>What does it mean to analyse an algorithm?</li><li>What is worst case performance?</li><li>What is the definition of <span class="math align-center">$O(f(n))$</span>, <span class="math align-center">$\theta(f(n)$</span>, and
<span class="math align-center">$\Omega(f(n))$</span>?</li><li>What are some of the basic properties of <span class="math align-center">$O()$</span>,<span class="math align-center">$\theta()$</span>, and
<span class="math align-center">$\Omega()$</span>.</li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-2>Lecture 2</h1><h2 id=todays-topics-divide-and-conquer-and-algorithm-analysis>Today&rsquo;s topics: Divide and Conquer and Algorithm Analysis</h2><ul><li>Divide and Conquer, in particular how to derive a recurrence
relation for the running time.</li><li>More on $O$,$\Theta$, and $\Omega$</li><li>The Master theorem and how to apply it.</li></ul><h2 id=slides-used>Slides used</h2><ul><li><a href=https://ad2-uu-se.github.io/slides/02-algo-analysis.pdf rel=external target=_blank>Algorithm analysis and the master
theorem</a></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li><p>Chapter 3 and 4 (except 4.6) of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or Chapter 3 and 4 (except 4.6
and 4.7) of
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</p></li><li><p>You might find the following slides useful: <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/05DivideAndConquerI.pdf rel=external target=_blank>Divide and Conquer
I</a>
which has some more examples on algorithm analysis, and
<a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/05DivideAndConquerII.pdf rel=external target=_blank>Divide and Conquer
II</a>
that has information on the master theorem.</p></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><p>You should know much more about the Big O notation. In particular</p><ol><li>General algebra with <span class="math align-center">$O$</span>, <span class="math align-center">$\theta$</span> and <span class="math align-center">$\Omega$</span>. For example when
is <span class="math align-center">$O(f(n)) \leq O(g(n))$</span>?</li><li>Constant time <span class="math align-center">$O(1)$</span>.</li><li>Linear time <span class="math align-center">$O(n)$</span>, polynomial time, exponential time</li><li>The rate of different asymptotic growths.</li></ol><p>Further you should know about divide and conquer an algorithm design
technique and the Analysis of Divide and Conquer using recurrence
relations. You should understand and be able to reproduce a simple
divide and conquer analysis of an algorithm such as binary search or
merge sort. You should understand how to go from recurrence relations
such as
<span class="math align-center">$$
T(n) = aT(n/b) + f(n)
$$</span>
to asymptotic analysis of the function $T(n)$. For which functions $g$
is the following statement true:
<span class="math align-center">$$
T(n) \in O(g(n))
$$</span></p><p>Although I do not expect expect you understand the proof, you should
try to get an intuition of the different cases of the master theorem.</p><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-3>Lecture 3</h1><p>Guest Lecture by Frej Knutar Lewander</p><h2 id=todays-topic-graphs-revision>Today&rsquo;s topic: Graphs revision</h2><ul><li><p>Revision on Digraphs/Digraphs: <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/03Graphs.pdf rel=external target=_blank>Slides
1-24</a>
Although some of this will be revision, you should pay attention to
how the graph representation effects the time complexity.</p></li><li><p><a href=https://ad2-uu-se.github.io/slides/03_frej_ad2.pdf rel=external target=_blank>Some hints and Tips on using Python for your assignments</a></p></li></ul><h2 id=slides>Slides</h2><ul><li>Slides 1-24, 33-43 of
<a href=http://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/03Graphs.pdf rel=external target=_blank>Graphs.pdf</a></li><li><a href=https://ad2-uu-se.github.io/slides/03_frej_ad2.pdf rel=external target=_blank>Slides on Data Structures in Python</a></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li>Chapter 22, except 22.4 of <a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a> or
Chapter 20, 20.1-20.3 of
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li><li>Chapter 24 Pages 643-650 and Section 24.3 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or chapter 22 (22.1, 22.2
22.3) of <a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>What did I forget from my previous courses?<ul><li>What is a graph? What is a digraph?</li><li>What is a good API for graphs?</li><li>How can they be represented?</li><li>Depth-first and breadth-first search.</li></ul></li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-4>Lecture 4</h1><h2 id=todays-topic-dynamic-programming>Today&rsquo;s topic: Dynamic Programming</h2><ul><li>Dynamic programming. Introduction.</li></ul><h2 id=slides>Slides</h2><ul><li>The slides can be found <a href=https://ad2-uu-se.github.io/slides/04_dynamic_programming_intro.pdf rel=external target=_blank>here</a></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li>Chapter 15, 15.1, 15.2 ,15.3, 15.4 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or Chapter 14, 14.1 , 14.2, 14.3 and 14.4 of
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>What is dynamic programming? Simple example dynamic programming as
Memorisation.</li><li>Some example dynamic programs.</li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-5>Lecture 5</h1><h2 id=todays-topic-dynamic-programming>Today&rsquo;s topic: Dynamic Programming</h2><ul><li>More on Dynamic Programming, Knapsack and an example.</li><li>Pseudo Polynomial vs. Polynomial.</li></ul><h2 id=links-to-slides>Links to Slides</h2><ul><li>The slides can be found <a href=https://ad2-uu-se.github.io/slides/05_dynamic_programming_cont.pdf rel=external target=_blank>here</a></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li><p>All of Chapter 15 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a> or all of
Chapter 14 of
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</p></li><li><p>The textbook does not say that much about pseudo-polynomial time and
the 0-1 Knapsack problem, even though it is an important
concept. There there is plenty of material on the internet. I suggest
that you start with the Wikipedia entries on <a href=https://en.wikipedia.org/wiki/Pseudo-polynomial_time rel=external target=_blank>Pseudo-polynomial
time</a> and the
<a href=https://en.wikipedia.org/wiki/Knapsack_problem rel=external target=_blank>Knapsack
problem</a>. You also
might find these
<a href=https://courses.csail.mit.edu/6.006/fall11/rec/rec21_knapsack.pdf rel=external target=_blank>notes</a>
useful.</p></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>Yet more dynamic programming examples</li><li>How to decompose a problem using Dynamic Programming</li><li>Optimal substructure</li><li>The difference between polynomial and pseudo-polynomial time. Ask
yourself why isn&rsquo;t the dynamic program for 0-1 Knapsack polynomial
time?</li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-6>Lecture 6</h1><h2 id=todays-topics-greedy-algorithms>Today&rsquo;s topics: Greedy Algorithms</h2><ul><li>Introduction to Greedy <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/04GreedyAlgorithmsI.pdf rel=external target=_blank>Slides
1-15</a>.<ul><li>We will look a greedy algorithm for the coin-change problem. This only
works with certain denomination coins. You should understand the
proof of why it works, and when it works.</li><li>Interval scheduling. Again we met a dynamic programming solution
before, here we will look at a simple greedy algorithm and
understand why it is correct.</li></ul></li><li>Shortest Paths as a greedy algorithm. <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/04GreedyAlgorithmsII.pdf rel=external target=_blank>Slides 1-16</a></li><li>All-Pairs Shortest path using Dynamic programming (The
â€£ Bellmanâ€“Fordâ€“Moore algorithm). <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/06DynamicProgrammingII.pdf rel=external target=_blank>Slides
33-41</a></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li>Chapter 16 except 16.4 and 16.5 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or Chapter 15, 15.1,15.2 and
15.3 of
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>How do I set up shortest paths as a dynamic program? How do I avoid cycles?</li><li>How does Dijkstraâ€™s algorithm work? Why is it correct?</li><li>What is a greedy algorithm?<ul><li>How do greedy algorithms compare with dynamic programming?</li><li>Are Greedy algorithms always optimal?</li></ul></li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-7>Lecture 7</h1><h2 id=todays-topics-minimal-spanning-trees>Today&rsquo;s topics: Minimal Spanning Trees.</h2><ul><li>Minimal Spanning Trees, Prim&rsquo;s algorithm.</li><li>slides 20-49 of <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/04GreedyAlgorithmsII.pdf rel=external target=_blank>Greedy Algorithms
II</a></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li>Chapter 23 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or Chapter 21 of
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>What is a minimal spanning tree?</li><li>Why is the greedy algorithm correct?</li><li>How does Prim&rsquo;s Algorithm work?</li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lectures-89>Lectures 8,9</h1><h2 id=network-flows>Network Flows</h2><p>When I do these lectures live, it normally takes me 3 lectures to go
through the material slowly and do lots of examples. This is a list
of topics that are needed to under network flows. You goal should be
to understand each topic.</p><ul><li>Definition of flow network.</li><li>The minimum-cut problem.</li><li>The maximum flow problem.</li><li>The definition of a residual network.</li><li>An Augmented path.</li><li>The statement of the Min-cut, max-flow theorem.</li><li>The Fordâ€“Fulkerson algorithm.</li><li>How to use the max-flow algorithm for maximum bipartite matching.</li></ul><h2 id=lecture-8>Lecture 8</h2><ul><li>Introduction to <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/07NetworkFlowI.pdf rel=external target=_blank>NetworkFlow
I</a>
Slides 1-23 and <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/07DemoFordFulkerson.pdf rel=external target=_blank>Demo of Ford-Fulkerson</a></li></ul><h2 id=lecture-9>Lecture 9</h2><ul><li><p>Alternative mathematical API. Flows that are Skew Symmetric flows,
that is $f(u,v)= -
f(v,u)$. We&rsquo;ll do this on the blackboard, but skew symmetric flows
are a bit counter intuitive, but they make the proofs and
implementation easier. Take a look at the presentation at
<a href=https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm rel=external target=_blank>Wikipedia</a>. This
is not examined, and I won&rsquo;t go into much detail.</p></li><li><p>Min-Cut Max-Flow duality slides 25-36 of
<a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/07NetworkFlowI.pdf rel=external target=_blank>NetworkFlow
I</a></p></li><li><p>Bipartite matching slides 1-17 of <a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/07NetworkFlowII.pdf rel=external target=_blank>NetworkFlow
II</a>.</p></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li>Chapter 26, except 26.4 and 26.5 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or Chapter 24 of
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-set-of-lectures>What should I know by the end of this set of lectures?</h2><ul><li>Do I understand the definitions of a flow network, min-cuts and
maximum flows?</li><li>Why does the naive greedy algorithm for maximum flow fail?</li><li>The relation between augmented paths and residual networks.</li><li>What is the relationship between flows and cuts?</li><li>What is the relationship between negative flows and residual
networks?</li><li>What does the min-cut max-flow algorithm tell us and how does it
help us to derive an algorithm?</li><li>What is bipartite matching? What are its applications?</li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lectures-10-and-11>Lectures 10 and 11</h1><h2 id=todays-topic-p-vs-np>Today&rsquo;s topic: P vs NP</h2><p>This will be a not so formal introduction to P and NP. Every computer
scientist should know something about NP complete problems. If you
know that a problem is NP complete, then you know that it is very hard
to find an optimal solution.</p><ul><li>The definition of P and NP</li><li>The definition of Reduction and NP Hardness</li><li>NP Completeness</li><li>Some NP Complete Problems.</li><li>What now? What courses should I take to learn more about algorithms
and optimisation?</li></ul><p>This material is examined.</p><h2 id=links-to-slides-and--other-material>Links to Slides and other material.</h2><p>These lectures will given by <a href="https://katalog.uu.se/empinfo/?id=N99-130" rel=external target=_blank>Pierre
Flener</a>.</p><p>The slides for the lecture can be found <a href=https://ad2-uu-se.github.io/slides/34-PversusNP.pdf rel=external target=_blank>here</a></p><img src=https://ad2-uu-se.github.io/slides/34_whiteboard1.jpg>
<img src=https://ad2-uu-se.github.io/slides/34_whiteboard2.jpg><h2 id=reading-guide>Reading Guide</h2><ul><li>All of Chapter 34 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or
<a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-set-of-lecture>What should I know by the end of this set of lecture?</h2><ul><li>The definition of NP? What has guessing a solution got to do with
complexity?</li><li>How do reductions work?</li><li>What is a complete problem for a complexity class?</li><li>You should know some NP-complete problems and have enough idea about
how reductions work so that you can decide if your problem is
NP-complete or not.</li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-12>Lecture 12</h1><h2 id=todays-topic-union-find>Today&rsquo;s topic: Union Find</h2><ul><li>Disjoint-set data-type. What is the API and some applications?</li><li>Naive representation: Sets represented as trees.</li><li>Representing trees as arrays, and Naive linking.</li><li>Link by Size</li><li>Link by Rank</li><li>Path compression</li><li>Analysis of run time.</li></ul><h2 id=slides>Slides</h2><p>I used slides 1 to 41 from
<a href=https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/UnionFind.pdf rel=external target=_blank>UnionFind</a>.</p><h2 id=reading-guide>Reading Guide</h2><ul><li>These <a href=https://people.eecs.berkeley.edu/~vazirani/algorithms/chap5.pdf rel=external target=_blank>notes</a>
contain useful information on greedy algorithms in general and section
5.1.4 is on Union Find. The best source is the textbook Chapter 21
(excluding section 21.4) of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or
Chapter 19 (excluding 19.4) of <a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=link-to-online-lectures-for-further-study>Link to online lectures for further study.</h2><p>Both <a href=https://www.youtube.com/channel/UCD8yeTczadqdARzQUp29PJw rel=external target=_blank>William
Fist</a> and
<a href=https://www.youtube.com/channel/UC7FzTMO4rKvlqIyU5vwzFKQ rel=external target=_blank>Josh Hug</a>
cover the same material, although Josh Hug takes it much more slowly.</p><ul><li><a href=https://www.youtube.com/channel/UCD8yeTczadqdARzQUp29PJw rel=external target=_blank>William Fist</a> has a number of useful lectures on Union-Find<ul><li><a href=https://youtu.be/ibjEGG7ylHk rel=external target=_blank>Introducton</a>.</li><li><a href=https://youtu.be/JZBQLXgSGfs rel=external target=_blank>Application</a>.</li><li><a href=https://youtu.be/0jNmHPfA_yE rel=external target=_blank>Union and Find Operations</a> with
trees and arrays.</li><li><a href=https://youtu.be/VHRhJWacxis rel=external target=_blank>Path Compression</a></li></ul></li><li><a href=https://www.youtube.com/channel/UC7FzTMO4rKvlqIyU5vwzFKQ rel=external target=_blank>Josh Hug</a><ul><li><a href=https://youtu.be/JNa8BRRs8L4 rel=external target=_blank>Introduction</a> to the Union Find API</li><li><a href=https://youtu.be/W6Dckcv8PIo rel=external target=_blank>Quick Find</a></li><li><a href=https://youtu.be/RY7UCusguGg rel=external target=_blank>Quick Union</a></li><li><a href=https://youtu.be/xc9s9wdaSdU rel=external target=_blank>Weighted Quick Union</a></li><li><a href=https://youtu.be/DZKzDebT4gU rel=external target=_blank>Path Compression</a></li></ul></li></ul><h2 id=what-should-i-know-by-the-end-of-this-set-of-lecture>What should I know by the end of this set of lecture?</h2><ul><li><p>What is the union-find API?</p></li><li><p>What are some of the applications of union-find?</p></li><li><p>How can I use trees to represent sets?</p></li><li><p>How do I represent sets of trees as a forest?</p></li><li><p>What are the different strategies for combining trees? Link by Size
and Link by Rank.</p></li><li><p>What is path compression? How does this improve the complexity of
union-find? Note that if you go deeply into the analysis of
union-find you will come to amortised analysis. This is the
analysis of the complexity of an algorithm over
multiple-runs. Amortised analysis is not part of this course, but
it is part of <a href="https://www.uu.se/en/admissions/master/selma/kursplan/?kKod=1DL481" rel=external target=_blank>AD3 -
1DL481</a>
that is normally taught by <a href="https://katalog.uu.se/empinfo/?id=N99-130" rel=external target=_blank>Pierre
Flener</a></p></li></ul><footer class=footline></footer></article><article class=default><header class=headline></header><h1 id=lecture-13>Lecture 13</h1><h2 id=todays-topic-string-matching>Today&rsquo;s topic: String Matching</h2><ul><li>The Rabin-Karp algorithm for fast string matching.</li></ul><h2 id=slides>Slides</h2><ul><li><a href=https://ad2-uu-se.github.io/slides/11_string_matching.pdf rel=external target=_blank>Slides</a></li></ul><h2 id=reading-guide>Reading Guide</h2><ul><li>Chapter 32 except sections 32.3 and 32.4 of
<a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/1f653j1/alma991002384899707596 rel=external target=_blank>CLRS3</a>
or <a href="https://uub.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991018351660807596&context=L&vid=46LIBRIS_UUB:UUB" rel=external target=_blank>CLRS4</a>.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-set-of-lecture>What should I know by the end of this set of lecture?</h2><ul><li>How does Rabin-Karp work? What is the clever idea with
hash-functions.</li><li>How does Rabin-Karp compare with brute force string matching?</li></ul><footer class=footline></footer></article></section></div></main></div><script src=/js/clipboard.min.js?1731417181 defer></script><script src=/js/perfect-scrollbar.min.js?1731417181 defer></script><script>function useMathJax(e){window.MathJax=Object.assign(window.MathJax||{},{tex:{inlineMath:[["\\(","\\)"],["$","$"]],displayMath:[["\\[","\\]"],["$$","$$"]]},options:{enableMenu:!1}},e)}useMathJax(JSON.parse("{}"))</script><script id=MathJax-script async src=/js/mathjax/tex-mml-chtml.js?1731417181></script><script src=/js/theme.js?1731417181 defer></script></body></html>